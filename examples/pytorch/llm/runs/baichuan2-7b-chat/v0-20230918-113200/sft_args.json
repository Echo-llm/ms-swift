{
  "model_type": "baichuan2-7b-chat",
  "sft_type": "lora",
  "template_type": "baichuan",
  "output_dir": "runs/baichuan2-7b-chat",
  "ddp_backend": null,
  "seed": 42,
  "resume_from_ckpt": null,
  "dtype": "bf16",
  "ignore_args_error": false,
  "dataset": "advertise-gen",
  "dataset_split_seed": 42,
  "train_dataset_sample": -1,
  "dataset_test_ratio": 0.01,
  "system": "you are a helpful assistant!",
  "max_length": 2048,
  "quantization_bit": 4,
  "bnb_4bit_comp_dtype": "bf16",
  "bnb_4bit_quant_type": "nf4",
  "bnb_4bit_use_double_quant": true,
  "lora_target_modules": [
    "o_proj",
    "down_proj",
    "W_pack",
    "gate_proj",
    "up_proj"
  ],
  "lora_rank": 8,
  "lora_alpha": 32,
  "lora_dropout_p": 0.0,
  "gradient_checkpointing": false,
  "batch_size": 1,
  "eval_batch_size": 1,
  "num_train_epochs": 1,
  "max_steps": -1,
  "optim": "adamw_torch",
  "learning_rate": 0.0001,
  "weight_decay": 0.0,
  "gradient_accumulation_steps": 16,
  "max_grad_norm": 0.5,
  "predict_with_generate": false,
  "lr_scheduler_type": "cosine",
  "warmup_ratio": 0.03,
  "eval_steps": 100,
  "save_steps": 100,
  "only_save_model": false,
  "save_total_limit": 2,
  "logging_steps": 10,
  "dataloader_num_workers": 1,
  "push_to_hub": false,
  "hub_model_id": "baichuan2-7b-chat-lora",
  "hub_private_repo": true,
  "hub_strategy": "every_save",
  "hub_token": null,
  "test_oom_error": false,
  "use_flash_attn": "auto",
  "max_new_tokens": 1024,
  "do_sample": true,
  "temperature": 0.9,
  "top_k": 50,
  "top_p": 0.9,
  "torch_dtype": "torch.bfloat16",
  "fp16": false,
  "bf16": true,
  "bnb_4bit_compute_dtype": "torch.bfloat16",
  "load_in_4bit": true,
  "load_in_8bit": false,
  "train_sampler_random": true
}